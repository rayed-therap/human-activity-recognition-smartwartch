{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "from util import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00507/wisdm-dataset.zip'\n",
    "file_name = url.split('/')[-1]\n",
    "\n",
    "if not os.path.exists(file_name):\n",
    "    with requests.get(url, stream=True) as response, open(file_name, 'wb') as file:\n",
    "        for chunk in response.iter_content(chunk_size=1024):\n",
    "            file.write(chunk)\n",
    "    with zipfile.ZipFile(file_name) as zip_file:\n",
    "        zip_file.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data to memory and write to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data'\n",
    "DATA_PATH = 'data/har.csv'\n",
    "RAW_DATA_DIR = 'wisdm-dataset/raw/watch'\n",
    "ACTIVITY_MAP = {\n",
    "    'A' : 'walking',\n",
    "    'B' : 'jogging', \n",
    "    'C' : 'stairs', \n",
    "    'D' : 'sitting', \n",
    "    'E' : 'standing'\n",
    "} \n",
    "\n",
    "def read_watch_data():\n",
    "    if os.path.exists(DATA_PATH):\n",
    "        return pd.read_csv(DATA_PATH)\n",
    "    sensor_dfs = []\n",
    "    activity_map = get_activity_map()\n",
    "    for sensor in ['accel', 'gyro']:\n",
    "        files = sorted(glob.glob(os.path.join(os.path.join(RAW_DATA_DIR, sensor), '*.txt')))\n",
    "        df = pd.concat([pd.read_csv(file, header=None) for file in files], axis=0, ignore_index=True)\n",
    "        df.columns = ['subject', 'activity', 'timestamp'] + [sensor + '_' + axis for axis in 'xyz']\n",
    "        df[df.columns[-1]] = df[df.columns[-1]].str.replace(';', '', regex=False).astype(float)\n",
    "        df = df.loc[df['activity'].isin(ACTIVITY_MAP.keys())]\n",
    "        df['activity'] = df['activity'].map(ACTIVITY_MAP)\n",
    "        sensor_dfs.append(df)\n",
    "    har_df = pd.merge(sensor_dfs[0], sensor_dfs[1], on=sensor_dfs[0].columns[0:3].tolist())\n",
    "    har_df = har_df.dropna()\n",
    "    har_df = har_df.drop_duplicates()\n",
    "    os.makedirs(DATA_DIR, exist_ok=True)\n",
    "    har_df.to_csv(DATA_PATH, index=False)\n",
    "    return har_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>activity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>accel_x</th>\n",
       "      <th>accel_y</th>\n",
       "      <th>accel_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1600</td>\n",
       "      <td>walking</td>\n",
       "      <td>90426757696641</td>\n",
       "      <td>4.972757</td>\n",
       "      <td>-0.158317</td>\n",
       "      <td>6.696732</td>\n",
       "      <td>0.314944</td>\n",
       "      <td>-1.022277</td>\n",
       "      <td>-0.309962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1600</td>\n",
       "      <td>walking</td>\n",
       "      <td>90426807196641</td>\n",
       "      <td>3.253720</td>\n",
       "      <td>-0.191835</td>\n",
       "      <td>6.107758</td>\n",
       "      <td>0.387382</td>\n",
       "      <td>-0.618541</td>\n",
       "      <td>-0.048972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1600</td>\n",
       "      <td>walking</td>\n",
       "      <td>90426856696641</td>\n",
       "      <td>2.801216</td>\n",
       "      <td>-0.155922</td>\n",
       "      <td>5.997625</td>\n",
       "      <td>0.070999</td>\n",
       "      <td>-0.209480</td>\n",
       "      <td>-0.195978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1600</td>\n",
       "      <td>walking</td>\n",
       "      <td>90426906196641</td>\n",
       "      <td>3.770868</td>\n",
       "      <td>-1.051354</td>\n",
       "      <td>7.731027</td>\n",
       "      <td>0.037975</td>\n",
       "      <td>0.254976</td>\n",
       "      <td>-0.156563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1600</td>\n",
       "      <td>walking</td>\n",
       "      <td>90426955696641</td>\n",
       "      <td>4.661511</td>\n",
       "      <td>0.169689</td>\n",
       "      <td>9.684695</td>\n",
       "      <td>0.073129</td>\n",
       "      <td>0.719431</td>\n",
       "      <td>-0.001035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject activity       timestamp   accel_x   accel_y   accel_z    gyro_x  \\\n",
       "0     1600  walking  90426757696641  4.972757 -0.158317  6.696732  0.314944   \n",
       "1     1600  walking  90426807196641  3.253720 -0.191835  6.107758  0.387382   \n",
       "2     1600  walking  90426856696641  2.801216 -0.155922  5.997625  0.070999   \n",
       "3     1600  walking  90426906196641  3.770868 -1.051354  7.731027  0.037975   \n",
       "4     1600  walking  90426955696641  4.661511  0.169689  9.684695  0.073129   \n",
       "\n",
       "     gyro_y    gyro_z  \n",
       "0 -1.022277 -0.309962  \n",
       "1 -0.618541 -0.048972  \n",
       "2 -0.209480 -0.195978  \n",
       "3  0.254976 -0.156563  \n",
       "4  0.719431 -0.001035  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(884901, 9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "har_df = read_watch_data()\n",
    "display(har_df.head())\n",
    "display(har_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "har_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None):\n",
    "    display(pd.pivot_table(har_df, index=har_df.columns[:2].tolist(), aggfunc='count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Readings for subjects 1637, 1638, 1639, and 1640 look out of 'shape'. Data points most likely got dropped because of varying timestamps. Let's plot to confirm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sensor_readings(sensor, subject, start=0, end=1024):\n",
    "    for activity in ACTIVITY_MAP.values():\n",
    "        data = har_df.query(f'subject == {subject} and activity == \"{activity}\"')[start:end]\n",
    "        if len(data) == 0:\n",
    "            continue\n",
    "        fig, (ax0, ax1, ax2) = plt.subplots(nrows=3, figsize=(20, 10), sharex=True)\n",
    "        plot_axis(ax0, data['timestamp'], data[sensor + '_x'], 'X-Axis')\n",
    "        plot_axis(ax1, data['timestamp'], data[sensor + '_y'], 'Y-Axis')\n",
    "        plot_axis(ax2, data['timestamp'], data[sensor + '_z'], 'Z-Axis')\n",
    "        plt.subplots_adjust(hspace=0.2)\n",
    "        fig.suptitle(sensor.upper() + ' : ' + activity.upper())\n",
    "        plt.subplots_adjust(top=0.90)\n",
    "        plt.show()\n",
    "\n",
    "def plot_axis(ax, x, y, title):\n",
    "    ax.plot(x, y, 'r')\n",
    "    ax.set_title(title)\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.set_ylim([min(y) - np.std(y), max(y) + np.std(y)])\n",
    "    ax.set_xlim([min(x), max(x)])\n",
    "    ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sensor_readings('accel', 1637)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping data of subjects 1637 to 1640 inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "har_df = har_df.loc[~har_df['subject'].isin([1637, 1638, 1639, 1640])].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None):\n",
    "    display(pd.pivot_table(har_df, index=har_df.columns[:2].tolist(), aggfunc='count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "har_df['activity'].value_counts().plot(kind='bar', title='Activity Counts', colors=['r', 'g', 'b', 'y', 'k'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 60 # corresponding to 3 secs (20 * 3). Data was sampled at 20 Hz.\n",
    "COLUMNS = ['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']\n",
    "DIMS = len(COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "har_df[COLUMNS] = scaler.fit_transform(har_df[COLUMNS])\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "har_df['activity'] = encoder.fit_transform(har_df['activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "    \n",
    "for index, data in har_df.groupby(['subject', 'activity'], sort=False):\n",
    "    data = data[COLUMNS].values\n",
    "    label = index[1]\n",
    "    for i in range(0, len(data) - SEQ_LEN, SEQ_LEN):\n",
    "        X.append(np.expand_dims(data[i:i+SEQ_LEN], axis=0))\n",
    "        y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate(X)\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=3, input_shape=(SEQ_LEN, DIMS)),\n",
    "#     tf.keras.layers.MaxPool1D(),\n",
    "#     tf.keras.layers.Conv1D(filters=64, kernel_size=3),\n",
    "#     tf.keras.layers.MaxPool1D(),\n",
    "#     tf.keras.layers.LSTM(units=64, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(units=64),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=5, activation='softmax')\n",
    "])\n",
    "\n",
    "# This function keeps the learning rate at 0.001 for the first ten epochs\n",
    "# and decreases it exponentially after that.\n",
    "def scheduler(epoch):\n",
    "    if epoch < 10:\n",
    "        return 0.001\n",
    "    return 0.001 * tf.math.exp(0.1 * (10 - epoch))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size=32, \n",
    "                    epochs=100, \n",
    "                    validation_split=0.1, \n",
    "                    callbacks=[\n",
    "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10), \n",
    "                        tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-3)\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['lr'], label='lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "accuracy = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "plt.plot(accuracy, label='accuracy')\n",
    "# plt.plot(loss, label='loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loss, eval_accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
